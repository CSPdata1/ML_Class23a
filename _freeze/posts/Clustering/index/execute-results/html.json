{
  "hash": "cdbf0a6997f2bff90e41c67c0df91c20",
  "result": {
    "markdown": "---\ntitle: Clustering\nauthor: Carlos Saint-Preux\ndate: '2023-12-10'\ncategories:\n  - news\n  - code\n  - analysis\nimage: image.jpg\n---\n\n# A Deep Dive into Clustering with Machine Learning\n\n## Introduction:\n\nClustering is a powerful technique in machine learning that involves grouping similar data points together based on certain features or characteristics. It has a wide range of applications, from customer segmentation in marketing to anomaly detection in cybersecurity. In this blog post, we will explore the concept of clustering, its types, and delve into practical examples using machine learning code and visualizations.\n\n![](images/IMG_0333.JPG)\n\n## 1. understanding Clustering\n\nClustering is an unsupervised learning technique where the algorithm identifies patterns and groups within a dataset without predefined labels. The primary goal is to maximize intra-cluster similarity while minimizing inter-cluster similarity. Common algorithms for clustering include K-Means, hierarchical clustering, and DBSCAN.\n\n## 2. K-Means Clustering: \n\nK-Means is one of the most popular clustering algorithms. It partitions the dataset into 'k' clusters, with each cluster represented by its centroid. The algorithm iteratively assigns data points to the nearest centroid and updates the centroids until convergence.\n\nLet's implement K-Means clustering using Python and the famous Iris dataset:\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\n# Import necessary libraries\nimport numpy as np\nimport pandas as pd\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\nfrom sklearn import datasets\n\n# Load the Iris dataset\niris = datasets.load_iris()\nX = iris.data\n\n# Apply K-Means clustering\nkmeans = KMeans(n_clusters=3, random_state=42)\nkmeans.fit(X)\n\n# Visualize the clusters\nplt.scatter(X[:, 0], X[:, 1], c=kmeans.labels_, cmap='viridis')\nplt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s=300, c='red')\nplt.title('K-Means Clustering on Iris Dataset')\nplt.xlabel('Sepal Length (cm)')\nplt.ylabel('Sepal Width (cm)')\nplt.show()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n/Users/carlossaint-preux/anaconda3/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning:\n\nThe default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-2-output-2.png){width=589 height=449}\n:::\n:::\n\n\nIn the above code, we apply K-Means clustering to the Iris dataset and visualize the clusters along with their centroids.\n\n## 3. Hierarchical Clustering \n\nHierarchical clustering builds a tree-like hierarchy of clusters. This technique is useful for understanding the relationships between clusters at different levels of granularity. We'll use the Agglomerative Hierarchical Clustering algorithm for this example.\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\n# Import necessary libraries\nfrom scipy.cluster.hierarchy import dendrogram, linkage\n\n# Apply Hierarchical Clustering\nZ = linkage(X, 'ward')\n\n# Visualize the hierarchical clustering\nplt.figure(figsize=(10, 5))\ndendrogram(Z)\nplt.title('Hierarchical Clustering Dendrogram')\nplt.xlabel('Iris Samples')\nplt.ylabel('Distance')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-3-output-1.png){width=809 height=449}\n:::\n:::\n\n\nIn this code, we use hierarchical clustering on the Iris dataset and visualize the resulting dendrogram.\n\n## Conclusion:\n\nClustering is a versatile tool in machine learning, providing insights into patterns and structures within datasets. In this blog post, we explored K-Means and hierarchical clustering, implemented them using Python, and visualized the results. These techniques are valuable for various applications, such as customer segmentation, anomaly detection, and more.\n\nExperiment with different datasets and clustering algorithms to gain a deeper understanding of their capabilities and limitations. As the field of machine learning continues to evolve, clustering remains a fundamental and powerful tool for data analysis.\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}