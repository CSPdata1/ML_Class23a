# Importing necessary libraries
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
# Generating synthetic data
np.random.seed(42)
X = 2 * np.random.rand(100, 1)
y = 4 + 3 * X + np.random.randn(100, 1)
# Splitting the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
# Creating and training the linear regression model
lin_reg = LinearRegression()
lin_reg.fit(X_train, y_train)
# Making predictions on the test set
y_pred = lin_reg.predict(X_test)
# Plotting the scatter plot
plt.scatter(X_test, y_test, color='blue', label='Actual Data')
# Plotting the regression line
plt.plot(X_test, y_pred, color='red', linewidth=3, label='Linear Regression Line')
# Adding labels and legend
plt.xlabel('X')
plt.ylabel('y')
plt.title('Linear Regression')
plt.legend()
# Displaying the plot
plt.show()
from sklearn.preprocessing import PolynomialFeatures
# Generating synthetic data with a quadratic relationship
y_nonlinear = 1 + 2 * X + 0.5 * X**2 + np.random.randn(100, 1)
# Transforming features to include quadratic term
poly_features = PolynomialFeatures(degree=2, include_bias=False)
X_poly = poly_features.fit_transform(X)
# Splitting the data into training and testing sets
X_poly_train, X_poly_test, y_poly_train, y_poly_test = train_test_split(X_poly, y_nonlinear, test_size=0.2, random_state=42)
# Creating and training the linear regression model with quadratic features
lin_reg_nonlinear = LinearRegression()
lin_reg_nonlinear.fit(X_poly_train, y_poly_train)
# Making predictions on the test set
y_poly_pred = lin_reg_nonlinear.predict(X_poly_test)
from sklearn.preprocessing import PolynomialFeatures
# Generating synthetic data with a quadratic relationship
y_nonlinear = 1 + 2 * X + 0.5 * X**2 + np.random.randn(100, 1)
# Transforming features to include quadratic term
poly_features = PolynomialFeatures(degree=2, include_bias=False)
X_poly = poly_features.fit_transform(X)
# Splitting the data into training and testing sets
X_poly_train, X_poly_test, y_poly_train, y_poly_test = train_test_split(X_poly, y_nonlinear, test_size=0.2, random_state=42)
# Creating and training the linear regression model with quadratic features
lin_reg_nonlinear = LinearRegression()
lin_reg_nonlinear.fit(X_poly_train, y_poly_train)
# Making predictions on the test set
y_poly_pred = lin_reg_nonlinear.predict(X_poly_test)
# Sorting X_test for better visualization
X_test_sorted, y_poly_pred_sorted = zip(*sorted(zip(X_test, y_poly_pred)))
# Plotting the scatter plot
plt.scatter(X_test, y_poly_test, color='blue', label='Actual Data')
# Plotting the quadratic regression curve
plt.plot(X_test_sorted, y_poly_pred_sorted, color='green', linewidth=3, label='Quadratic Regression Curve')
# Adding labels and legend
plt.xlabel('X')
plt.ylabel('y')
plt.title('Nonlinear Regression - Quadratic')
plt.legend()
# Displaying the plot
plt.show()
# Calculating residuals for linear regression
residuals_linear = y_test - y_pred
# Calculating residuals for quadratic regression
residuals_nonlinear = y_poly_test - y_poly_pred
# Plotting residuals for linear regression
plt.scatter(X_test, residuals_linear, color='red', label='Linear Regression Residuals')
# Plotting residuals for quadratic regression
plt.scatter(X_test, residuals_nonlinear, color='green', label='Quadratic Regression Residuals')
# Adding a horizontal line at y=0
plt.axhline(y=0, color='black', linestyle='--', linewidth=2)
# Adding labels and legend
plt.xlabel('X')
plt.ylabel('Residuals')
plt.title('Residuals Plot')
plt.legend()
# Displaying the plot
plt.show()
# Sorting X_test for better visualization
X_test_sorted, y_pred_sorted = zip(*sorted(zip(X_test, y_pred)))
# Plotting the scatter plot
plt.scatter(X_test, y_test, color='blue', label='Actual Data')
# Plotting the linear regression line
plt.plot(X_test_sorted, y_pred_sorted, color='red', linewidth=3, label='Linear Regression Line')
# Sorting X_test for quadratic regression
X_test_sorted, y_poly_pred_sorted = zip(*sorted(zip(X_test, y_poly_pred)))
# Plotting the quadratic regression curve
plt.plot(X_test_sorted, y_poly_pred_sorted, color='green', linewidth=3, label='Quadratic Regression Curve')
# Adding labels and legend
plt.xlabel('X')
plt.ylabel('y')
plt.title('Model Comparison - Linear vs. Quadratic')
plt.legend()
# Displaying the plot
plt.show()
# Example code for Logistic Regression
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
# Assuming 'X' is the feature matrix and 'y' is the target variable
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
# Create and train the model
model = LogisticRegression()
model.fit(X_train, y_train)
# Make predictions
y_pred = model.predict(X_test)
# Evaluate accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy}")
# Example code for Logistic Regression
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
# Assuming 'X' is the feature matrix and 'y' is the target variable
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
# Create and train the model
model = LogisticRegression()
model.fit(X_train, y_train)
# Make predictions
y_pred = model.predict(X_test)
# Evaluate accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy}")
# Example code for Logistic Regression
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
# Assuming 'X' is the feature matrix and 'y' is the target variable
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
# Reshape y variable
y_train = y_train.ravel()
# Create and train the model
model = LogisticRegression()
model.fit(X_train, y_train)
# Make predictions
y_pred = model.predict(X_test)
# Evaluate accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy}")
# Example code for Logistic Regression
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
# Assuming 'X' is the feature matrix and 'y' is the target variable
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
# Reshape y variable
y_train = y_train.ravel()
# Create and train the model
model = LogisticRegression()
model.fit(X_train, y_train)
# Reshape X variable
X_test = X_test.reshape(-1, 1)
# Make predictions
y_pred = model.predict(X_test)
# Evaluate accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy}")
print(f"Accuracy: {accuracy}")
library(reticulate)
py_install("pandas")
library(reticulate)
# Example code for Logistic Regression
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
# Assuming 'X' is the feature matrix and 'y' is the target variable
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
# Reshape y variable
y_train = y_train.ravel()
# Create and train the model
model = LogisticRegression()
model.fit(X_train, y_train)
# Reshape X variable
X_test = X_test.reshape(-1, 1)
# Make predictions
y_pred = model.predict(X_test)
# Evaluate accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy}")
library(reticulate)
# Example code for Logistic Regression
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
# Assuming 'X' is the feature matrix and 'y' is the target variable
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
# Reshape y variable
y_train = y_train.ravel()
# Create and train the model
model = LogisticRegression()
model.fit(X_train, y_train)
# Reshape X variable
X_test = X_test.reshape(-1, 1)
# Make predictions
y_pred = model.predict(X_test)
# Evaluate accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy}")
# Example code for Logistic Regression
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
# Assuming 'X' is the feature matrix and 'y' is the target variable
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
# Reshape y variable
y_train = y_train.ravel()
# Create and train the model
model = LogisticRegression()
model.fit(X_train, y_train)
# Reshape X variable
X_test = X_test.reshape(-1, 1)
# Make predictions
y_pred = model.predict(X_test)
# Evaluate accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy}")
# Example code for Confusion Matrix, ROC Curve, and Precision-Recall Curve
from sklearn.metrics import confusion_matrix, roc_curve, precision_recall_curve, auc
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='g', cmap='Blues')
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()
# ROC Curve
fpr, tpr, _ = roc_curve(y_test, model.predict_proba(X_test)[:,1])
roc_auc = auc(fpr, tpr)
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.show()
# Precision-Recall Curve
precision, recall, _ = precision_recall_curve(y_test, model.predict_proba(X_test)[:,1])
plt.figure(figsize=(8, 6))
plt.plot(recall, precision, color='green', lw=2, label='Precision-Recall curve')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.legend(loc='upper right')
plt.show()
# Example code for Confusion Matrix, ROC Curve, and Precision-Recall Curve
from sklearn.metrics import confusion_matrix, roc_curve, precision_recall_curve, auc
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='g', cmap='Blues')
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()
# ROC Curve
fpr, tpr, _ = roc_curve(y_test, model.predict_proba(X_test)[:,1])
roc_auc = auc(fpr, tpr)
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.show()
# Precision-Recall Curve
precision, recall, _ = precision_recall_curve(y_test, model.predict_proba(X_test)[:,1])
plt.figure(figsize=(8, 6))
plt.plot(recall, precision, color='green', lw=2, label='Precision-Recall curve')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.legend(loc='upper right')
plt.show()
#setting up the stage
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import sklearn as sl
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
x = np.arange(1, 25).reshape(12, 2)
y = np.array([0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0])
x
y
x_train, x_test, y_train, y_test = train_test_split(x, y)
x_train
x_test
y_train
y_test
X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)
# Create and train the model
model = LogisticRegression()
model.fit(X_train, y_train)
# Make predictions
y_pred = model.predict(X_test)
# Evaluate accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy}")
###
# Example code for Decision Trees
from sklearn.tree import DecisionTreeClassifier
# Create and train the model
model = DecisionTreeClassifier()
model.fit(X_train, y_train)
# Make predictions
y_pred = model.predict(X_test)
# Evaluate accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy}")
####
# Example code for Random Forests
from sklearn.ensemble import RandomForestClassifier
# Create and train the model
model = RandomForestClassifier()
model.fit(X_train, y_train)
# Make predictions
y_pred = model.predict(X_test)
# Evaluate accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy}")
#setting up the stage
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import sklearn as sl
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
x = np.arange(1, 25).reshape(12, 2)
y = np.array([0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0])
x
y
x_train, x_test, y_train, y_test = train_test_split(x, y)
x_train
x_test
y_train
y_test
X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)
# Create and train the model
model = LogisticRegression()
model.fit(X_train, y_train)
# Make predictions
y_pred = model.predict(X_test)
# Evaluate accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy}")
#setting up the stage
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import sklearn as sl
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
x = np.arange(1, 25).reshape(12, 2)
y = np.array([0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0])
x
y
x_train, x_test, y_train, y_test = train_test_split(x, y)
x_train
x_test
y_train
y_test
X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)
# Create and train the model
model = LogisticRegression()
model.fit(X_train, y_train)
# Make predictions
y_pred = model.predict(X_test)
# Evaluate accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy}")
###
# Example code for Decision Trees
from sklearn.tree import DecisionTreeClassifier
# Example code for Confusion Matrix, ROC Curve, and Precision-Recall Curve
from sklearn.metrics import confusion_matrix, roc_curve, precision_recall_curve, auc
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='g', cmap='Blues')
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()
# ROC Curve
fpr, tpr, _ = roc_curve(y_test, model.predict_proba(X_test)[:,1])
roc_auc = auc(fpr, tpr)
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.show()
# Precision-Recall Curve
precision, recall, _ = precision_recall_curve(y_test, model.predict_proba(X_test)[:,1])
plt.figure(figsize=(8, 6))
plt.plot(recall, precision, color='green', lw=2, label='Precision-Recall curve')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.legend(loc='upper right')
plt.show()
#setting up the stage
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import sklearn as sl
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
x = np.arange(1, 25).reshape(12, 2)
y = np.array([0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0])
x
y
x_train, x_test, y_train, y_test = train_test_split(x, y)
x_train
x_test
y_train
y_test
X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)
# Create and train the model
model = LogisticRegression()
model.fit(X_train, y_train)
# Make predictions
y_pred = model.predict(X_test)
# Evaluate accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy}")
